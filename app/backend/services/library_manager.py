"""
çµ±ä¸€Libraryæ•¸æ“šç®¡ç†æœå‹™
è§£æ±ºæ•¸æ“šæ•£å¸ƒå’Œä¸ä¸€è‡´å•é¡Œ
"""
import json
import logging
from pathlib import Path
from typing import List, Dict, Any, Optional
from dataclasses import dataclass
from database.init_db import get_connection
from vi_search.constants import DATA_DIR

logger = logging.getLogger(__name__)

@dataclass
class LibraryCleanupResult:
    """æ¸…ç†çµæœ"""
    library_name: str
    success: bool
    cleaned_components: List[str]
    failed_components: List[str]
    errors: List[str]

class LibraryManager:
    """çµ±ä¸€çš„Libraryæ•¸æ“šç®¡ç†æœå‹™"""
    
    def __init__(self, prompt_content_db, settings_service, db_manager):
        self.prompt_content_db = prompt_content_db
        self.settings_service = settings_service
        self.db_manager = db_manager
        self.cache_file = DATA_DIR / "file_hash_cache.json"
    
    def delete_library_completely(self, library_name: str) -> LibraryCleanupResult:
        """
        å®Œå…¨åˆªé™¤libraryåŠå…¶æ‰€æœ‰ç›¸é—œæ•¸æ“š
        å¯¦ç¾ç´šè¯åˆªé™¤å’ŒéŒ¯èª¤æ¢å¾©
        """
        result = LibraryCleanupResult(
            library_name=library_name,
            success=True,
            cleaned_components=[],
            failed_components=[],
            errors=[]
        )
        
        logger.info(f"Starting complete deletion of library: {library_name}")
        
        # 1. åˆªé™¤Azure Search Index
        try:
            self.prompt_content_db.remove_db(library_name)
            result.cleaned_components.append("azure_search_index")
            logger.info(f"âœ… Deleted Azure Search Index: {library_name}")
        except Exception as e:
            error_msg = f"Failed to delete Azure Search Index: {str(e)}"
            result.errors.append(error_msg)
            result.failed_components.append("azure_search_index")
            logger.error(error_msg)
        
        # 2. åˆªé™¤SQLiteæ•¸æ“šåº«è¨­å®š
        try:
            with get_connection() as conn:
                cursor = conn.execute("DELETE FROM library_settings WHERE library_name = ?", (library_name,))
                deleted_settings = cursor.rowcount
                conn.commit()
            result.cleaned_components.append(f"library_settings({deleted_settings})")
            logger.info(f"âœ… Deleted {deleted_settings} library settings")
        except Exception as e:
            error_msg = f"Failed to delete library settings: {str(e)}"
            result.errors.append(error_msg)
            result.failed_components.append("library_settings")
            logger.error(error_msg)
        
        # 3. åˆªé™¤videoè¨˜éŒ„
        try:
            deleted_videos = self.db_manager.delete_library_videos(library_name)
            result.cleaned_components.append(f"video_records({deleted_videos})")
            logger.info(f"âœ… Deleted {deleted_videos} video records")
        except Exception as e:
            error_msg = f"Failed to delete video records: {str(e)}"
            result.errors.append(error_msg)
            result.failed_components.append("video_records")
            logger.error(error_msg)
        
        # 4. æ¸…ç†æ–‡ä»¶hashç·©å­˜
        try:
            cleaned_cache = self._clean_file_hash_cache(library_name)
            result.cleaned_components.append(f"file_hash_cache({cleaned_cache})")
            logger.info(f"âœ… Cleaned {cleaned_cache} hash cache entries")
        except Exception as e:
            error_msg = f"Failed to clean file hash cache: {str(e)}"
            result.errors.append(error_msg)
            result.failed_components.append("file_hash_cache")
            logger.error(error_msg)
        
        # 5. æ¸…ç†ä»»å‹™è¨˜éŒ„
        try:
            deleted_tasks = self._clean_library_tasks(library_name)
            result.cleaned_components.append(f"tasks({deleted_tasks})")
            logger.info(f"âœ… Cleaned {deleted_tasks} task records")
        except Exception as e:
            error_msg = f"Failed to clean task records: {str(e)}"
            result.errors.append(error_msg)
            result.failed_components.append("tasks")
            logger.error(error_msg)
        
        # åˆ¤æ–·æ•´é«”æˆåŠŸèˆ‡å¦
        result.success = len(result.failed_components) == 0
        
        if result.success:
            logger.info(f"ğŸ‰ Complete deletion SUCCESS for library: {library_name}")
        else:
            logger.error(f"âŒ Complete deletion PARTIAL FAILURE for library: {library_name}")
            logger.error(f"Failed components: {result.failed_components}")
        
        return result
    
    def _clean_file_hash_cache(self, library_name: str) -> int:
        """æ¸…ç†æ–‡ä»¶hashç·©å­˜ä¸­çš„libraryç›¸é—œæ¢ç›®"""
        if not self.cache_file.exists():
            return 0
        
        # è®€å–ç·©å­˜æ–‡ä»¶
        with open(self.cache_file, 'r', encoding='utf-8') as f:
            cache_data = json.load(f)
        
        # æ‰¾å‡ºè¦åˆªé™¤çš„æ¢ç›®
        keys_to_delete = []
        for key, value in cache_data.items():
            if isinstance(value, dict) and value.get('library_name') == library_name:
                keys_to_delete.append(key)
        
        # åˆªé™¤æ¢ç›®
        for key in keys_to_delete:
            del cache_data[key]
        
        # å¯«å›æ–‡ä»¶
        with open(self.cache_file, 'w', encoding='utf-8') as f:
            json.dump(cache_data, f, indent=2, ensure_ascii=False)
        
        return len(keys_to_delete)
    
    def _clean_library_tasks(self, library_name: str) -> int:
        """æ¸…ç†èˆ‡libraryç›¸é—œçš„ä»»å‹™è¨˜éŒ„"""
        try:
            with get_connection() as conn:
                cursor = conn.execute("""
                    DELETE FROM tasks 
                    WHERE library_name = ? OR task_data LIKE ?
                """, (library_name, f'%{library_name}%'))
                deleted_count = cursor.rowcount
                conn.commit()
                return deleted_count
        except Exception:
            # å¦‚æœtasksè¡¨ä¸å­˜åœ¨ï¼Œè¿”å›0
            return 0
    
    def verify_library_consistency(self, library_name: str) -> Dict[str, Any]:
        """é©—è­‰libraryæ•¸æ“šä¸€è‡´æ€§"""
        result = {
            'library_name': library_name,
            'consistent': True,
            'issues': [],
            'components': {}
        }
        
        # æª¢æŸ¥å„çµ„ä»¶æ˜¯å¦å­˜åœ¨
        components = {
            'azure_search_index': self._check_azure_index_exists(library_name),
            'library_settings': self._check_library_settings_exists(library_name),
            'video_records': self._check_video_records_exist(library_name),
            'file_hash_cache': self._check_file_hash_cache_exists(library_name)
        }
        
        result['components'] = components
        
        # æª¢æŸ¥ä¸ä¸€è‡´
        existing_components = [k for k, v in components.items() if v]
        if len(existing_components) > 0 and len(existing_components) < len(components):
            result['consistent'] = False
            result['issues'].append(f"Partial data found in: {existing_components}")
        
        return result
    
    def _check_azure_index_exists(self, library_name: str) -> bool:
        """æª¢æŸ¥Azure Search Indexæ˜¯å¦å­˜åœ¨"""
        try:
            available_dbs = self.prompt_content_db.get_available_dbs()
            return library_name in available_dbs
        except Exception:
            return False
    
    def _check_library_settings_exists(self, library_name: str) -> bool:
        """æª¢æŸ¥libraryè¨­å®šæ˜¯å¦å­˜åœ¨"""
        try:
            with get_connection() as conn:
                cursor = conn.execute("SELECT COUNT(*) FROM library_settings WHERE library_name = ?", (library_name,))
                return cursor.fetchone()[0] > 0
        except Exception:
            return False
    
    def _check_video_records_exist(self, library_name: str) -> bool:
        """æª¢æŸ¥videoè¨˜éŒ„æ˜¯å¦å­˜åœ¨"""
        try:
            videos = self.db_manager.get_library_videos(library_name)
            return len(videos) > 0
        except Exception:
            return False
    
    def _check_file_hash_cache_exists(self, library_name: str) -> bool:
        """æª¢æŸ¥æ–‡ä»¶hashç·©å­˜ä¸­æ˜¯å¦æœ‰ç›¸é—œæ¢ç›®"""
        try:
            if not self.cache_file.exists():
                return False
            
            with open(self.cache_file, 'r', encoding='utf-8') as f:
                cache_data = json.load(f)
            
            for value in cache_data.values():
                if isinstance(value, dict) and value.get('library_name') == library_name:
                    return True
            return False
        except Exception:
            return False
    
    def list_all_libraries_with_status(self) -> List[Dict[str, Any]]:
        """åˆ—å‡ºæ‰€æœ‰libraryåŠå…¶ç‹€æ…‹"""
        libraries = []
        
        # å¾Azure Searchç²å–æ‰€æœ‰index
        try:
            azure_indexes = self.prompt_content_db.get_available_dbs()
        except Exception:
            azure_indexes = []
        
        # å¾æ•¸æ“šåº«ç²å–æ‰€æœ‰libraryè¨­å®š
        try:
            with get_connection() as conn:
                cursor = conn.execute("SELECT DISTINCT library_name FROM library_settings")
                db_libraries = [row[0] for row in cursor.fetchall()]
        except Exception:
            db_libraries = []
        
        # åˆä½µæ‰€æœ‰libraryåç¨±
        all_library_names = set(azure_indexes + db_libraries)
        
        for lib_name in all_library_names:
            status = self.verify_library_consistency(lib_name)
            libraries.append({
                'name': lib_name,
                'consistent': status['consistent'],
                'issues': status['issues'],
                'components': status['components']
            })
        
        return libraries
    
    def cleanup_inconsistent_libraries(self) -> List[LibraryCleanupResult]:
        """è‡ªå‹•æ¸…ç†æ‰€æœ‰ä¸ä¸€è‡´çš„libraries"""
        libraries = self.list_all_libraries_with_status()
        results = []
        
        for lib in libraries:
            if not lib['consistent']:
                logger.info(f"Cleaning up inconsistent library: {lib['name']}")
                result = self.delete_library_completely(lib['name'])
                results.append(result)
        
        return results